{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langfuse\n",
    "# !pip install google-generativeai\n",
    "# !pip install langchain-google-genai\n",
    "# !pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "from langfuse.openai import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-8182bd5e-8041-4524-8195-2e70b0a5518d\"\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-9bbcc91b-50d4-4973-81b4-84ab28c505a5\"\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGFUSE_SECRET_KEY = \"sk-lf-8182bd5e-8041-4524-8195-2e70b0a5518d\"\n",
    "# LANGFUSE_PUBLIC_KEY = \"pk-lf-9bbcc91b-50d4-4973-81b4-84ab28c505a5\"\n",
    "# LANGFUSE_HOST = \"https://us.cloud.langfuse.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse = Langfuse(\n",
    " secret_key=\"sk-lf-8182bd5e-8041-4524-8195-2e70b0a5518d\",\n",
    " public_key=\"pk-lf-9bbcc91b-50d4-4973-81b4-84ab28c505a5\",\n",
    " host=\"https://us.cloud.langfuse.com\"\n",
    ")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Langfuse client is disabled since no public_key was provided as a parameter or environment variable 'LANGFUSE_PUBLIC_KEY'. See our docs: https://langfuse.com/docs/sdk/python/low-level-sdk#initialize-client\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\BBS_Org_Langfuse\\bbs_llm_proj_lf.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m  poem \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   messages\u001b[39m=\u001b[39m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m    {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mYou are a blogger. Create a summary about this best friend\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgenerate-poem\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m  )\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m  \u001b[39mreturn\u001b[39;00m poem\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m summary_generator(\u001b[39m\"\u001b[39;49m\u001b[39mHarry Porter\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\langfuse\\decorators\\langfuse_decorator.py:256\u001b[0m, in \u001b[0;36mLangfuseDecorator._sync_observe.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_exception(observation, e)\n\u001b[0;32m    257\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalize_call(\n\u001b[0;32m    259\u001b[0m         observation, result, capture_output, transform_to_string\n\u001b[0;32m    260\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\langfuse\\decorators\\langfuse_decorator.py:517\u001b[0m, in \u001b[0;36mLangfuseDecorator._handle_exception\u001b[1;34m(self, observation, e)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m observation:\n\u001b[0;32m    514\u001b[0m     _observation_params_context\u001b[39m.\u001b[39mget()[observation\u001b[39m.\u001b[39mid]\u001b[39m.\u001b[39mupdate(\n\u001b[0;32m    515\u001b[0m         level\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mERROR\u001b[39m\u001b[39m\"\u001b[39m, status_message\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(e)\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\langfuse\\decorators\\langfuse_decorator.py:254\u001b[0m, in \u001b[0;36mLangfuseDecorator._sync_observe.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(observation, e)\n",
      "\u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\BBS_Org_Langfuse\\bbs_llm_proj_lf.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m@observe\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummary_generator\u001b[39m(hero):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m  HP \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   messages \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m    {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwho is the best friend of the hero in Harry Porter movie?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m    {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: hero}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   ],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mget-capital\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m  )\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m  poem \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   messages\u001b[39m=\u001b[39m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m    {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mYou are a blogger. Create a summary about this best friend\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgenerate-poem\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m  )\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti.chowrasia/js/Agentic_AI_Apps/BBS_Org_Langfuse/bbs_llm_proj_lf.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m  \u001b[39mreturn\u001b[39;00m poem\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\openai\\_utils\\_proxy.py:20\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m---> 20\u001b[0m     proxied \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_proxied__()\n\u001b[0;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(proxied, LazyProxy):\n\u001b[0;32m     22\u001b[0m         \u001b[39mreturn\u001b[39;00m proxied  \u001b[39m# pyright: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\openai\\_utils\\_proxy.py:55\u001b[0m, in \u001b[0;36mLazyProxy.__get_proxied__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_proxied__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m---> 55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load__()\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\openai\\_module_client.py:12\u001b[0m, in \u001b[0;36mChatProxy.__load__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__load__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m resources\u001b[39m.\u001b[39mChat:\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_client()\u001b[39m.\u001b[39mchat\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\openai\\__init__.py:328\u001b[0m, in \u001b[0;36m_load_client\u001b[1;34m()\u001b[0m\n\u001b[0;32m    312\u001b[0m         _client \u001b[39m=\u001b[39m _AzureModuleClient(  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    313\u001b[0m             api_version\u001b[39m=\u001b[39mapi_version,\n\u001b[0;32m    314\u001b[0m             azure_endpoint\u001b[39m=\u001b[39mazure_endpoint,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m             http_client\u001b[39m=\u001b[39mhttp_client,\n\u001b[0;32m    325\u001b[0m         )\n\u001b[0;32m    326\u001b[0m         \u001b[39mreturn\u001b[39;00m _client\n\u001b[1;32m--> 328\u001b[0m     _client \u001b[39m=\u001b[39m _ModuleClient(\n\u001b[0;32m    329\u001b[0m         api_key\u001b[39m=\u001b[39;49mapi_key,\n\u001b[0;32m    330\u001b[0m         organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m    331\u001b[0m         project\u001b[39m=\u001b[39;49mproject,\n\u001b[0;32m    332\u001b[0m         base_url\u001b[39m=\u001b[39;49mbase_url,\n\u001b[0;32m    333\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    334\u001b[0m         max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[0;32m    335\u001b[0m         default_headers\u001b[39m=\u001b[39;49mdefault_headers,\n\u001b[0;32m    336\u001b[0m         default_query\u001b[39m=\u001b[39;49mdefault_query,\n\u001b[0;32m    337\u001b[0m         http_client\u001b[39m=\u001b[39;49mhttp_client,\n\u001b[0;32m    338\u001b[0m     )\n\u001b[0;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m _client\n\u001b[0;32m    341\u001b[0m \u001b[39mreturn\u001b[39;00m _client\n",
      "File \u001b[1;32mc:\\Users\\jyoti.chowrasia\\js\\Agentic_AI_Apps\\.venv\\lib\\site-packages\\openai\\_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    108\u001b[0m     api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m api_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m api_key\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "@observe()\n",
    "def summary_generator(hero):\n",
    " HP = openai.chat.completions.create(\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  messages = [\n",
    "   {\"role\":\"system\", \"content\": \"who is the best friend of the hero in Harry Porter movie?\"},\n",
    "   {\"role\": \"user\", \"content\": hero}\n",
    "  ],\n",
    "  name = \"get-capital\",\n",
    " ).choices[0].message.content\n",
    "\n",
    " poem = openai.chat.completions.create(\n",
    "  messages=[\n",
    "   {\"role\": \"system\",\"content\": \"You are a blogger. Create a summary about this best friend\"},\n",
    "   {\"role\": \"user\", \"content\": HP}\n",
    "  ],\n",
    "  name = \"generate-poem\",\n",
    " ).choices[0].message.content\n",
    "\n",
    " return poem\n",
    "\n",
    "summary_generator(\"Harry Porter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @observe()\n",
    "# def my_story():\n",
    "#  return openai.chat.completions.create(\n",
    "#   model=\"gemini-pro\",\n",
    "#   max_tokens=100,\n",
    "#   messages=[\n",
    "#    {\"role\": \"system\", \"content\":\"You are a great story teller\"},\n",
    "#    {\"role\":\"user\", \"content\":\"once upon a time in a galaxy\"}\n",
    "#   ]\n",
    "#  ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @observe()\n",
    "# def main():\n",
    "#  return my_story()\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_API_KEY = \"AIzaSyBaTn1Cg2ZWcvjGQ7Nc1zUoy0bFmWWBucM\"\n",
    "# genai.configure(api_key = GOOGLE_API_KEY)\n",
    "# model = ChatGoogleGenerativeAI(model= 'gemini-pro', google_api_key = GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def llm(x):\n",
    "#  return model.invoke(x).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in langfuse, if we want any function to log we have to use decorator @observe\n",
    "# @observe(as_type='generation')\n",
    "# def story_teller(model, input_, model_object):\n",
    "#  langfuse_context.update_current_observation(\n",
    "#   input= input_,\n",
    "#   model=model\n",
    "# )\n",
    "#  return model_object(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @observe()\n",
    "# def main():\n",
    "#  prompt = \"Generate a story with Theme {}\".format(\"flower\")\n",
    "#  return story_teller('gemini-pro', prompt, llm)\n",
    "\n",
    "# for x in range(1):\n",
    "#  story = main()\n",
    "#  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langfuse.decorators import observe\n",
    "# from langfuse.openai import openai # OpenAI integration\n",
    " \n",
    "# @observe()\n",
    "# def story():\n",
    "#     return openai.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         max_tokens=100,\n",
    "#         messages=[\n",
    "#           {\"role\": \"system\", \"content\": \"You are a great storyteller.\"},\n",
    "#           {\"role\": \"user\", \"content\": \"Once upon a time in a galaxy far, far away...\"}\n",
    "#         ],\n",
    "#     ).choices[0].message.content\n",
    " \n",
    "# @observe()\n",
    "# def main():\n",
    "#     return story()\n",
    " \n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "import anthropic\n",
    " \n",
    "anthopic_client = anthropic.Anthropic()\n",
    " \n",
    "# Wrap LLM function with decorator\n",
    "@observe(as_type=\"generation\")\n",
    "def anthropic_completion(**kwargs):\n",
    "  # optional, extract some fields from kwargs\n",
    "  kwargs_clone = kwargs.copy()\n",
    "  input = kwargs_clone.pop('messages', None)\n",
    "  model = kwargs_clone.pop('model', None)\n",
    "  langfuse_context.update_current_observation(\n",
    "      input=input,\n",
    "      model=model,\n",
    "      metadata=kwargs_clone\n",
    "  )\n",
    " \n",
    "  response = anthopic_client.messages.create(**kwargs)\n",
    " \n",
    "  # See docs for more details on token counts and usd cost in Langfuse\n",
    "  # https://langfuse.com/docs/model-usage-and-cost\n",
    "  langfuse_context.update_current_observation(\n",
    "      usage_details={\n",
    "          \"input\": response.usage.input_tokens,\n",
    "          \"output\": response.usage.output_tokens\n",
    "      }\n",
    "  )\n",
    " \n",
    "  # return result\n",
    "  return response.content[0].text\n",
    " \n",
    "@observe()\n",
    "def main():\n",
    "  return anthropic_completion(\n",
    "      model=\"claude-3-opus-20240229\",\n",
    "      max_tokens=1024,\n",
    "      messages=[\n",
    "          {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
    "      ]\n",
    "  )\n",
    " \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
